{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bianyuan/.conda/envs/py310/lib/python3.10/site-packages/astroML/linear_model/linear_regression_errors.py:10: UserWarning: LinearRegressionwithErrors requires PyMC3 to be installed\n",
      "  warnings.warn('LinearRegressionwithErrors requires PyMC3 to be installed')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"/home/bianyuan/workspace/Grab_TNGgalaxy/\")\n",
    "# sys.path.append(\"./Grab_TNGgalaxy\")\n",
    "import illustris_python as il\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib widget\n",
    "run = 'TNG50'\n",
    "basePath = '/media/bianyuan/data-TNG-1/' + run + '-1/output'\n",
    "from astroML.plotting import setup_text_plots\n",
    "#Lets text in plots use latex\n",
    "# setup_text_plots(usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Tranfer SnapNum to Redshift'''\n",
    "\n",
    "import numpy as np\n",
    "import h5py, scipy\n",
    "from pynbody import units as units_conv\n",
    "\n",
    "Redshift_snapshot = np.loadtxt('/home/bianyuan/workspace/data/Redshift_snapshot.txt',comments='Snapshot')\n",
    "\n",
    "def redshift_snapshot(snapshots, datafile='/home/bianyuan/workspace/data/Redshift_snapshot.txt', return_opt=None):\n",
    "    snapshots0, redshifts0 = np.loadtxt(datafile, skiprows=1, unpack=True, usecols=[0, 2])\n",
    "    n_snap = np.size(snapshots)\n",
    "    if n_snap == 1: \n",
    "        redshifts = redshifts0[np.where(snapshots0 == snapshots)][0]\n",
    "    elif n_snap >1:\n",
    "        redshifts = np.zeros(n_snap)\n",
    "        for ii in range(n_snap): \n",
    "            if  snapshots[ii] is np.nan: \n",
    "                redshifts[ii] = np.nan\n",
    "            else:\n",
    "                redshifts[ii] = redshifts0[np.where(snapshots0 == snapshots[ii])][0]\n",
    "    if return_opt is None: \n",
    "        return redshifts\n",
    "    # elif return_opt == 'age':\n",
    "    #     return age(redshifts)\n",
    "    elif return_opt == 'FT':\n",
    "        return FT(redshifts)\n",
    "\n",
    "def _a_dot(a, h0, om_m, om_l):                                \n",
    "    om_k = 1.0 - om_m - om_l      \n",
    "    return h0 * a * np.sqrt(om_m * (a ** -3) + om_k * (a ** -2) + om_l)  \n",
    "\n",
    "def _a_dot_recip(*args):\n",
    "    return 1. / _a_dot(*args) \n",
    "\n",
    "# The formation time of stars in unit of Gyr\n",
    "def FT(redshift, h0=0.6774, OmegaM=0.3089, OmegaL=0.6911):\n",
    "    conv = units_conv.Unit(\"0.01 s Mpc km^-1\").ratio('Gyr')\n",
    "    redshift = 1./(1. + redshift)\n",
    "    ns = np.size(redshift)\n",
    "    if ns > 1:\n",
    "        FT = np.zeros(ns)\n",
    "        for ii in range(ns): FT[ii] = scipy.integrate.quad(_a_dot_recip, 0, redshift[ii], (h0, OmegaM, OmegaL))[0] * conv\n",
    "    else:\n",
    "        FT = scipy.integrate.quad(_a_dot_recip, 0, redshift, (h0, OmegaM, OmegaL))[0] * conv\n",
    "    return FT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Linux中，如果你想搜索一个文件夹中包含特定字段的文件，你可以使用 grep 命令。这个命令非常强大，可以在文件内容中搜索特定的文本模式。以下是一个基本的命令格式，用于在指定目录中搜索包含特定字段的文件：\n",
    "\n",
    "grep -r \"你的字段\" /path/to/directory\n",
    "\n",
    "grep 是搜索命令。\n",
    "-r 表示递归搜索，这意味着 grep 将在指定目录及其所有子目录中查找。\n",
    "\"你的字段\" 是你想搜索的文本。确保用引号包围，特别是如果文本中包含空格。\n",
    "/path/to/directory 是你想搜索的目录的路径。\n",
    "\n",
    "此命令将列出所有包含指定字段的文件及字段所在的行。如果你只想知道哪些文件包含该字段，而不关心具体的内容，可以使用 -l（小写L）选项：\n",
    "\n",
    "grep -rl \"你的字段\" /path/to/directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''在服务器上压缩文件'''\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def zip_folder(folder_path, zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n",
    "\n",
    "# 示例用法\n",
    "'''要压缩文件所在的文件夹'''\n",
    "folder_path = '/home/tnguser/pic/MRY_grp/nearby'\n",
    "'''压缩文件存放的路径'''\n",
    "zip_path = '/home/tnguser/pic/MRY_grp/nearby.zip'\n",
    "zip_folder(folder_path, zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''显示hdf5文件的结构'''\n",
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "file_meta = h5py.File('/home/tnguser/data/StarID/starID_1e7_gals_snap_40.hdf5', 'r')\n",
    "\n",
    "# Function to recursively print the data structure\n",
    "def print_structure(item, indent=\"\"):\n",
    "    if isinstance(item, h5py.Group):\n",
    "        print(indent + \"Group: \" + item.name)\n",
    "        for key in item.keys():\n",
    "            print_structure(item[key], indent + \"    \")\n",
    "    elif isinstance(item, h5py.Dataset):\n",
    "        print(indent + \"Dataset: \" + item.name)\n",
    "\n",
    "# Call the function to print the structure\n",
    "print_structure(file_meta)\n",
    "\n",
    "# Close the file\n",
    "file_meta.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
